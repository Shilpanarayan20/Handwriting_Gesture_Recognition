{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "9EDCYFTdaxkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeedForward(Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_hidden: int = 512):\n",
        "        super(FeedForward, self).__init__()\n",
        "\n",
        "        self.linear_1 = torch.nn.Linear(d_model, d_hidden)\n",
        "        self.linear_2 = torch.nn.Linear(d_hidden, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.linear_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "IkQO-PpJxxpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class Myloss(Module):\n",
        "    def __init__(self):\n",
        "        super(Myloss, self).__init__()\n",
        "        self.loss_function = CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, y_pre, y_true):\n",
        "        y_true = y_true.long()\n",
        "        loss = self.loss_function(y_pre, y_true)\n",
        "\n",
        "        return "
      ],
      "metadata": {
        "id": "-vyRFohCLMXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MultiHeadAttention(Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 q: int,\n",
        "                 v: int,\n",
        "                 h: int,\n",
        "                 device: str,\n",
        "                 mask: bool=False,\n",
        "                 dropout: float = 0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.W_q = torch.nn.Linear(d_model, q * h)\n",
        "        self.W_k = torch.nn.Linear(d_model, q * h)\n",
        "        self.W_v = torch.nn.Linear(d_model, v * h)\n",
        "\n",
        "        self.W_o = torch.nn.Linear(v * h, d_model)\n",
        "\n",
        "        self.device = device\n",
        "        self._h = h\n",
        "        self._q = q\n",
        "\n",
        "        self.mask = mask\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.score = None\n",
        "\n",
        "    def forward(self, x, stage):\n",
        "        Q = torch.cat(self.W_q(x).chunk(self._h, dim=-1), dim=0)\n",
        "        K = torch.cat(self.W_k(x).chunk(self._h, dim=-1), dim=0)\n",
        "        V = torch.cat(self.W_v(x).chunk(self._h, dim=-1), dim=0)\n",
        "\n",
        "        score = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self._q)\n",
        "        self.score = score\n",
        "\n",
        "        if self.mask and stage == 'train':\n",
        "            mask = torch.ones_like(score[0])\n",
        "            mask = torch.tril(mask, diagonal=0)\n",
        "            score = torch.where(mask > 0, score, torch.Tensor([-2**32+1]).expand_as(score[0]).to(self.device))\n",
        "\n",
        "        score = F.softmax(score, dim=-1)\n",
        "\n",
        "        attention = torch.matmul(score, V)\n",
        "\n",
        "        attention_heads = torch.cat(attention.chunk(self._h, dim=0), dim=-1)\n",
        "\n",
        "        self_attention = self.W_o(attention_heads)\n",
        "\n",
        "        return self_attention, self.score"
      ],
      "metadata": {
        "id": "H8Zd8f5RyAYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "import torch\n",
        "\n",
        "class Encoder(Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_hidden: int,\n",
        "                 q: int,\n",
        "                 v: int,\n",
        "                 h: int,\n",
        "                 device: str,\n",
        "                 mask: bool = False,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.MHA = MultiHeadAttention(d_model=d_model, q=q, v=v, h=h, mask=mask, device=device, dropout=dropout)\n",
        "        self.feedforward = FeedForward(d_model=d_model, d_hidden=d_hidden)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.layerNormal_1 = torch.nn.LayerNorm(d_model)\n",
        "        self.layerNormal_2 = torch.nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, stage):\n",
        "\n",
        "        residual = x\n",
        "        x, score = self.MHA(x, stage)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layerNormal_1(x + residual)\n",
        "\n",
        "        residual = x\n",
        "        x = self.feedforward(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layerNormal_2(x + residual)\n",
        "\n",
        "        return x, score"
      ],
      "metadata": {
        "id": "JUJt2uosxnJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "import torch\n",
        "from torch.nn import ModuleList\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Transformer(Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_input: int,\n",
        "                 d_channel: int,\n",
        "                 d_output: int,\n",
        "                 d_hidden: int,\n",
        "                 q: int,\n",
        "                 v: int,\n",
        "                 h: int,\n",
        "                 N: int,\n",
        "                 device: str,\n",
        "                 dropout: float = 0.1,\n",
        "                 pe: bool = False,\n",
        "                 mask: bool = False):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder_list_1 = ModuleList([Encoder(d_model=d_model,\n",
        "                                                  d_hidden=d_hidden,\n",
        "                                                  q=q,\n",
        "                                                  v=v,\n",
        "                                                  h=h,\n",
        "                                                  mask=mask,\n",
        "                                                  dropout=dropout,\n",
        "                                                  device=device) for _ in range(N)])\n",
        "\n",
        "        self.encoder_list_2 = ModuleList([Encoder(d_model=d_model,\n",
        "                                                  d_hidden=d_hidden,\n",
        "                                                  q=q,\n",
        "                                                  v=v,\n",
        "                                                  h=h,\n",
        "                                                  dropout=dropout,\n",
        "                                                  device=device) for _ in range(N)])\n",
        "\n",
        "        self.embedding_channel = torch.nn.Linear(d_channel, d_model)\n",
        "        self.embedding_input = torch.nn.Linear(d_input, d_model)\n",
        "\n",
        "        self.gate = torch.nn.Linear(d_model * d_input + d_model * d_channel, 2)\n",
        "        self.output_linear = torch.nn.Linear(d_model * d_input + d_model * d_channel, d_output)\n",
        "\n",
        "        self.pe = pe\n",
        "        self._d_input = d_input\n",
        "        self._d_model = d_model\n",
        "\n",
        "    def forward(self, x, stage):\n",
        "        \n",
        "        encoding_1 = self.embedding_channel(x)\n",
        "        input_to_gather = encoding_1\n",
        "\n",
        "        if self.pe:\n",
        "            pe = torch.ones_like(encoding_1[0])\n",
        "            position = torch.arange(0, self._d_input).unsqueeze(-1)\n",
        "            temp = torch.Tensor(range(0, self._d_model, 2))\n",
        "            temp = temp * -(math.log(10000) / self._d_model)\n",
        "            temp = torch.exp(temp).unsqueeze(0)\n",
        "            temp = torch.matmul(position.float(), temp)  # shape:[input, d_model/2]\n",
        "            pe[:, 0::2] = torch.sin(temp)\n",
        "            pe[:, 1::2] = torch.cos(temp)\n",
        "\n",
        "            encoding_1 = encoding_1 + pe\n",
        "\n",
        "        for encoder in self.encoder_list_1:\n",
        "            encoding_1, score_input = encoder(encoding_1, stage)\n",
        "\n",
        "        \n",
        "        encoding_2 = self.embedding_input(x.transpose(-1, -2))\n",
        "        channel_to_gather = encoding_2\n",
        "\n",
        "        for encoder in self.encoder_list_2:\n",
        "            encoding_2, score_channel = encoder(encoding_2, stage)\n",
        "\n",
        "\n",
        "        encoding_1 = encoding_1.reshape(encoding_1.shape[0], -1)\n",
        "        encoding_2 = encoding_2.reshape(encoding_2.shape[0], -1)\n",
        "\n",
        "        # gate\n",
        "        gate = F.softmax(self.gate(torch.cat([encoding_1, encoding_2], dim=-1)), dim=-1)\n",
        "        encoding = torch.cat([encoding_1 * gate[:, 0:1], encoding_2 * gate[:, 1:2]], dim=-1)\n",
        "\n",
        "\n",
        "        output = self.output_linear(encoding)\n",
        "\n",
        "        return output, encoding, score_input, score_channel, input_to_gather, channel_to_gather, gate"
      ],
      "metadata": {
        "id": "jxflB_zFyO4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "#setup_seed(30) \n",
        "\n",
        "\n",
        "EPOCH = 150\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.001\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
        "print(f'use device: {DEVICE}')\n",
        "\n",
        "d_model = 256\n",
        "d_hidden = 256\n",
        "q = 4\n",
        "v = 4\n",
        "h = 4\n",
        "N = 5\n",
        "dropout = 0.2\n",
        "\n",
        "X = np.load('/content/(N_W)X_Data.npy',allow_pickle=True)\n",
        "Y = np.load('/content/(N_W)Y_Data.npy',allow_pickle=True)\n",
        "\n",
        "\n",
        "train_dataset, test_dataset, y_train , y_test  = train_test_split(X, Y, test_size = 0.30, random_state = 150, shuffle=True)\n",
        "\n",
        "#train_dataset = np.load(\"/content/X_train_equal.npy\", allow_pickle=True)\n",
        "#test_dataset = np.load(\"/content/X_test_equal.npy\",allow_pickle=True)\n",
        "\n",
        "#y_train = np.load(\"/content/Y_train_equal.npy\",allow_pickle=True)\n",
        "#y_test = np.load(\"/content/Y_test_equal.npy\",allow_pickle=True)\n",
        "\n",
        "train_dataset = np.asarray(train_dataset).astype('float32')\n",
        "test_dataset = np.asarray(test_dataset).astype('float32')\n",
        "\n",
        "y_train = np.asarray(y_train).astype('float32')\n",
        "y_test = np.asarray(y_test).astype('float32')\n",
        "\n",
        "y_test = np.array(y_test).flatten()\n",
        "y_train = np.array(y_train).flatten()\n",
        "#y_train = tf.keras.utils.to_categorical(y_train)\n",
        "#y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "train_dataset = train_dataset.reshape((train_dataset.shape[0], 98, 2))\n",
        "test_dataset = test_dataset.reshape((test_dataset.shape[0], 98, 2))\n",
        "\n",
        "tensor_x = torch.Tensor(train_dataset) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(y_train)\n",
        "tensor_xx = torch.Tensor(test_dataset) # transform to torch tensor\n",
        "tensor_yy = torch.Tensor(y_test)\n",
        "\n",
        "my_dataset_train = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "my_dataset_test = TensorDataset(tensor_xx,tensor_yy)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(dataset=my_dataset_train, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=my_dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "DATA_LEN = train_dataset.shape[0]\n",
        "Data_Len = test_dataset.shape[0] \n",
        "d_input = 98  \n",
        "d_channel = 2 \n",
        "d_output = 2\n",
        "\n",
        "\n",
        "print('data structure: [lines, timesteps, features]')\n",
        "print(f'train data size: [{DATA_LEN, d_input, d_channel}]')\n",
        "print(f'test data size: [{Data_Len, d_input, d_channel}]')\n",
        "print(f'Number of classes: {d_output}')\n",
        "\n",
        "\n",
        "net = Transformer(d_model=d_model, d_input=d_input, d_channel=d_channel, d_output=d_output, d_hidden=d_hidden,\n",
        "                  q=q, v=v, h=h, N=N, dropout=dropout, device=DEVICE).to(DEVICE)\n",
        "\n",
        "loss_function = CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qJwQVyEJydOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_xx.shape"
      ],
      "metadata": {
        "id": "lCQ1q5RJJW33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_on_train = []\n",
        "correct_on_test = []\n",
        "predict = []\n",
        "\n",
        "\n",
        "loss_list = []\n",
        "time_cost = 0\n",
        "\n",
        "def test(dataloader, flag='test_set'):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            y_pre, _, _, _, _, _, _ = net(x, 'test')\n",
        "            _, label_index = torch.max(y_pre.data, dim=1)\n",
        "            total += label_index.shape[0]\n",
        "            correct += (label_index == y.long()).sum().item()\n",
        "            predict.append(label_index)\n",
        "\n",
        "            \n",
        "        if flag == 'test_set':\n",
        "            correct_on_test.append(round((100 * correct / total),2))\n",
        "        elif flag == 'train_set':\n",
        "            correct_on_train.append(round((100 * correct / total),2))\n",
        "        print(f'Accuracy on {flag}: %.2f %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "        return round((100 * correct / total),2)\n",
        "        return correct\n",
        "        \n"
      ],
      "metadata": {
        "id": "duGfR1qUsWUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def train():\n",
        "    net.train()\n",
        "    max_accuracy = 0\n",
        "    test_interval= 10\n",
        "    pbar = tqdm(total=EPOCH)\n",
        "    begin = time()\n",
        "    for index in range(EPOCH):\n",
        "       for i, (x, y) in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pre, _, _, _, _, _, _ = net(x.to(DEVICE), 'train')\n",
        "\n",
        "            loss = loss_function(y_pre, y.to(DEVICE).long())\n",
        "            #acc = test(train_dataloader, 'train_set')\n",
        "\n",
        "            print(f'Epoch:{index + 1}:\\t\\tloss:{loss.item()}')\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "metadata": {
        "id": "MFAyeSZH1mxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/sample_data/Model/model.pt'\n",
        "\n",
        "torch.save(net, PATH)"
      ],
      "metadata": {
        "id": "a-XgQRbdhtls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing\n"
      ],
      "metadata": {
        "id": "SCzPw7y7cYA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_dataloader)"
      ],
      "metadata": {
        "id": "tpteeRFoSE3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = torch.cat(predict)\n",
        "predict = torch.flatten(predict)\n",
        "predict = predict.detach().cpu().numpy()\n",
        "predict"
      ],
      "metadata": {
        "id": "K6cVbb3w0TLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy Score = \", accuracy_score(y_test, predict))"
      ],
      "metadata": {
        "id": "6HDdGFac_Azd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation\n"
      ],
      "metadata": {
        "id": "Hv_NAgE-ckck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "id": "xdW5IdZmAxCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (8,8),fontsize=14, normalize=True):\n",
        "     \n",
        "    if normalize:\n",
        "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        fmt = '.2f'\n",
        "    else:\n",
        "        fmt = 'd'\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt= fmt)\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "7SILKv7AAxLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
        " #                 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
        "   #                'X', 'Y', 'Z']\n",
        "\n",
        "\n",
        "#class_names = ['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #                  'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd'] \n",
        "\n",
        "#class_names = ['0','1','2','3','4','5','6','7','8','9','A',\n",
        " #                'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W',\n",
        "   #              'X', 'Y', 'Z','a',\n",
        "    #             'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "     #             'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
        "      #            'x', 'y', 'z']  \n",
        "\n",
        "\n",
        "class_names = ['Not Writing','Writing']                   \n",
        "print_confusion_matrix(cm, class_names)\n",
        "plt.savefig('Confusion_Matix_.png', dpi=300)\n"
      ],
      "metadata": {
        "id": "G96TUTw8AxOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#report = classification_report(y_test, predict,target_names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
        " #                  'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
        "   #                'X', 'Y', 'Z'])\n",
        "\n",
        "#report = classification_report(y_test, predict,target_names=['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #                  'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd']) \n",
        "\n",
        "#report = classification_report(y_test, predict,target_names= ['0','1','2','3','4','5','6','7','8','9','A',\n",
        " #                'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #               'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W',\n",
        "   #               'X', 'Y', 'Z','a',\n",
        "    #             'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "     #            'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
        "      #            'x', 'y', 'z']) \n",
        "\n",
        "\n",
        "report = classification_report(y_test, predict,target_names= ['Not Writing','Writing'])\n",
        "print(report)"
      ],
      "metadata": {
        "id": "76kdj0M2AxSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "print(report)"
      ],
      "metadata": {
        "id": "l8fFehaQA-LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Classification_Report_62.txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ],
      "metadata": {
        "id": "JMyJbtw9A-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "correct = [pred == true for pred, true in zip(predict, y_test)]\n",
        "correct = np.array(correct).flatten()\n",
        "print(Counter(correct))"
      ],
      "metadata": {
        "id": "vSPuBPFFA-Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "id": "yp7JFQEyOCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiedIndexes = np.where(y_test==predict)[0]\n",
        "misclassifiedIndexes = np.where(y_test!=predict)[0]"
      ],
      "metadata": {
        "id": "FnhXJGiI2j9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5az0WCReHKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}