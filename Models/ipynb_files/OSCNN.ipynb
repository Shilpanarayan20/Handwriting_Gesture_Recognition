{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRgel7ZeO0JG",
        "outputId": "0b5d059e-5de1-40b0-ce51-be6770943321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TuG_50ZChdQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24d9f04-f46f-4fe5-a8a0-fc0248180189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8463, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras import utils as np_utils \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from keras import utils as np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#Importing training set\n",
        "\n",
        "X = np.load(\"/content/(N_W)X_Data.npy\",allow_pickle=True)\n",
        "Y = np.load(\"/content/(N_W)Y_Data.npy\",allow_pickle=True)\n",
        "\n",
        "X_train, X_test, y_train , y_test  = train_test_split(X, Y, test_size = 0.30, random_state = 150, shuffle=True)\n",
        "\n",
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_test = np.asarray(X_test).astype('float32')\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 196, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 196,1))\n",
        "\n",
        "#Convert data into 3d tensor\n",
        "#X_train = np.reshape(X_train,(1721,132,1))\n",
        "#X_test = np.reshape(X_test,(574,132,1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train = tf.cast(X_train,dtype=tf.float32)\n",
        "X_test = tf.cast(X_test,dtype=tf.float32)\n",
        "y_train = y_train \n",
        "y_test = y_test\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "y_train=tf.cast(y_train,dtype=tf.float32)\n",
        "y_test=tf.cast(y_test,dtype=tf.float32)\n",
        "\n",
        "\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FCcImh6YHJZZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers.pooling import AveragePooling1D\n",
        "#Importing convolutional layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "#Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "#Input shape must be explicitly defined, DO NOT USE (None,shape)!!!\n",
        "\n",
        "classifier.add(Convolution1D(filters=8, kernel_size=1, activation=\"relu\")) \n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Convolution1D(filters=16, kernel_size=2, activation=\"relu\")) \n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Convolution1D(filters=16, kernel_size=3,activation=\"relu\"))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Convolution1D(filters=32, kernel_size=3,activation=\"relu\"))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "\n",
        "classifier.add(Convolution1D(filters=32, kernel_size=3,activation=\"relu\"))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#Flattening\n",
        "classifier.add(AveragePooling1D())\n",
        "classifier.add(Flatten())\n",
        "\n",
        "\n",
        "#Full Connection\n",
        "classifier.add(Dropout(0.3))\n",
        "classifier.add(Dense(2, activation = 'softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mRJnKkrUV1I",
        "outputId": "60ce5685-5962-4cbb-845e-49dcb6277d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9bdec82280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9bdec82280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133/133 [==============================] - 25s 89ms/step - loss: 0.4480 - accuracy: 0.8204\n",
            "Epoch 2/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.3656 - accuracy: 0.8517\n",
            "Epoch 3/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.3221 - accuracy: 0.8688\n",
            "Epoch 4/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.2855 - accuracy: 0.8827\n",
            "Epoch 5/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.2675 - accuracy: 0.8911\n",
            "Epoch 6/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.2468 - accuracy: 0.8999\n",
            "Epoch 7/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.2337 - accuracy: 0.9030\n",
            "Epoch 8/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.2266 - accuracy: 0.9100\n",
            "Epoch 9/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.2109 - accuracy: 0.9169\n",
            "Epoch 10/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.2068 - accuracy: 0.9165\n",
            "Epoch 11/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.1993 - accuracy: 0.9173\n",
            "Epoch 12/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1972 - accuracy: 0.9206\n",
            "Epoch 13/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1886 - accuracy: 0.9256\n",
            "Epoch 14/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1900 - accuracy: 0.9246\n",
            "Epoch 15/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1896 - accuracy: 0.9237\n",
            "Epoch 16/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1763 - accuracy: 0.9299\n",
            "Epoch 17/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1806 - accuracy: 0.9278\n",
            "Epoch 18/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1765 - accuracy: 0.9304\n",
            "Epoch 19/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1675 - accuracy: 0.9324\n",
            "Epoch 20/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1625 - accuracy: 0.9364\n",
            "Epoch 21/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1610 - accuracy: 0.9390\n",
            "Epoch 22/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1580 - accuracy: 0.9376\n",
            "Epoch 23/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.1536 - accuracy: 0.9376\n",
            "Epoch 24/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.1556 - accuracy: 0.9374\n",
            "Epoch 25/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1562 - accuracy: 0.9380\n",
            "Epoch 26/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1515 - accuracy: 0.9388\n",
            "Epoch 27/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.1464 - accuracy: 0.9433\n",
            "Epoch 28/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1458 - accuracy: 0.9443\n",
            "Epoch 29/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1388 - accuracy: 0.9453\n",
            "Epoch 30/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1378 - accuracy: 0.9469\n",
            "Epoch 31/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1397 - accuracy: 0.9423\n",
            "Epoch 32/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1341 - accuracy: 0.9486\n",
            "Epoch 33/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1284 - accuracy: 0.9491\n",
            "Epoch 34/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1282 - accuracy: 0.9506\n",
            "Epoch 35/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1264 - accuracy: 0.9505\n",
            "Epoch 36/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.1221 - accuracy: 0.9529\n",
            "Epoch 37/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.1266 - accuracy: 0.9501\n",
            "Epoch 38/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1191 - accuracy: 0.9525\n",
            "Epoch 39/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.1185 - accuracy: 0.9553\n",
            "Epoch 40/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1220 - accuracy: 0.9514\n",
            "Epoch 41/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1215 - accuracy: 0.9511\n",
            "Epoch 42/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1162 - accuracy: 0.9519\n",
            "Epoch 43/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.1152 - accuracy: 0.9531\n",
            "Epoch 44/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.1108 - accuracy: 0.9550\n",
            "Epoch 45/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1162 - accuracy: 0.9553\n",
            "Epoch 46/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1161 - accuracy: 0.9547\n",
            "Epoch 47/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.1118 - accuracy: 0.9560\n",
            "Epoch 48/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.1052 - accuracy: 0.9596\n",
            "Epoch 49/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.1029 - accuracy: 0.9609\n",
            "Epoch 50/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.1048 - accuracy: 0.9572\n",
            "Epoch 51/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1017 - accuracy: 0.9611\n",
            "Epoch 52/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1018 - accuracy: 0.9589\n",
            "Epoch 53/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1015 - accuracy: 0.9634\n",
            "Epoch 54/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1003 - accuracy: 0.9592\n",
            "Epoch 55/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1076 - accuracy: 0.9578\n",
            "Epoch 56/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0984 - accuracy: 0.9615\n",
            "Epoch 57/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0989 - accuracy: 0.9610\n",
            "Epoch 58/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0991 - accuracy: 0.9604\n",
            "Epoch 59/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.1035 - accuracy: 0.9584\n",
            "Epoch 60/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0984 - accuracy: 0.9610\n",
            "Epoch 61/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.1013 - accuracy: 0.9603\n",
            "Epoch 62/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.0933 - accuracy: 0.9630\n",
            "Epoch 63/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.0947 - accuracy: 0.9633\n",
            "Epoch 64/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0961 - accuracy: 0.9607\n",
            "Epoch 65/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0882 - accuracy: 0.9650\n",
            "Epoch 66/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0943 - accuracy: 0.9628\n",
            "Epoch 67/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0885 - accuracy: 0.9644\n",
            "Epoch 68/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0923 - accuracy: 0.9654\n",
            "Epoch 69/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0876 - accuracy: 0.9668\n",
            "Epoch 70/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0891 - accuracy: 0.9651\n",
            "Epoch 71/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0873 - accuracy: 0.9667\n",
            "Epoch 72/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0832 - accuracy: 0.9673\n",
            "Epoch 73/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0819 - accuracy: 0.9689\n",
            "Epoch 74/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0876 - accuracy: 0.9656\n",
            "Epoch 75/150\n",
            "133/133 [==============================] - 12s 89ms/step - loss: 0.0826 - accuracy: 0.9680\n",
            "Epoch 76/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0895 - accuracy: 0.9648\n",
            "Epoch 77/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0890 - accuracy: 0.9649\n",
            "Epoch 78/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0815 - accuracy: 0.9679\n",
            "Epoch 79/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0860 - accuracy: 0.9674\n",
            "Epoch 80/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0758 - accuracy: 0.9692\n",
            "Epoch 81/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0735 - accuracy: 0.9731\n",
            "Epoch 82/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0829 - accuracy: 0.9672\n",
            "Epoch 83/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0852 - accuracy: 0.9670\n",
            "Epoch 84/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0751 - accuracy: 0.9707\n",
            "Epoch 85/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0707 - accuracy: 0.9726\n",
            "Epoch 86/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0699 - accuracy: 0.9722\n",
            "Epoch 87/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0708 - accuracy: 0.9732\n",
            "Epoch 88/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0811 - accuracy: 0.9685\n",
            "Epoch 89/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0801 - accuracy: 0.9701\n",
            "Epoch 90/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.0784 - accuracy: 0.9688\n",
            "Epoch 91/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0746 - accuracy: 0.9709\n",
            "Epoch 92/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0740 - accuracy: 0.9724\n",
            "Epoch 93/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0708 - accuracy: 0.9721\n",
            "Epoch 94/150\n",
            "133/133 [==============================] - 12s 89ms/step - loss: 0.0764 - accuracy: 0.9718\n",
            "Epoch 95/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0723 - accuracy: 0.9726\n",
            "Epoch 96/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0769 - accuracy: 0.9707\n",
            "Epoch 97/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0743 - accuracy: 0.9724\n",
            "Epoch 98/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0669 - accuracy: 0.9753\n",
            "Epoch 99/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0743 - accuracy: 0.9708\n",
            "Epoch 100/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0740 - accuracy: 0.9720\n",
            "Epoch 101/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0736 - accuracy: 0.9715\n",
            "Epoch 102/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0691 - accuracy: 0.9715\n",
            "Epoch 103/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0722 - accuracy: 0.9718\n",
            "Epoch 104/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0777 - accuracy: 0.9690\n",
            "Epoch 105/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0706 - accuracy: 0.9721\n",
            "Epoch 106/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.0663 - accuracy: 0.9746\n",
            "Epoch 107/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0727 - accuracy: 0.9726\n",
            "Epoch 108/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0652 - accuracy: 0.9765\n",
            "Epoch 109/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0667 - accuracy: 0.9741\n",
            "Epoch 110/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0649 - accuracy: 0.9762\n",
            "Epoch 111/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0667 - accuracy: 0.9744\n",
            "Epoch 112/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0670 - accuracy: 0.9747\n",
            "Epoch 113/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0653 - accuracy: 0.9739\n",
            "Epoch 114/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0704 - accuracy: 0.9722\n",
            "Epoch 115/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0645 - accuracy: 0.9751\n",
            "Epoch 116/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0584 - accuracy: 0.9774\n",
            "Epoch 117/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0575 - accuracy: 0.9785\n",
            "Epoch 118/150\n",
            "133/133 [==============================] - 11s 82ms/step - loss: 0.0621 - accuracy: 0.9759\n",
            "Epoch 119/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0632 - accuracy: 0.9774\n",
            "Epoch 120/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0592 - accuracy: 0.9766\n",
            "Epoch 121/150\n",
            "133/133 [==============================] - 12s 87ms/step - loss: 0.0632 - accuracy: 0.9761\n",
            "Epoch 122/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0569 - accuracy: 0.9777\n",
            "Epoch 123/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0641 - accuracy: 0.9747\n",
            "Epoch 124/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0676 - accuracy: 0.9729\n",
            "Epoch 125/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0612 - accuracy: 0.9748\n",
            "Epoch 126/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0629 - accuracy: 0.9761\n",
            "Epoch 127/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0612 - accuracy: 0.9757\n",
            "Epoch 128/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0650 - accuracy: 0.9752\n",
            "Epoch 129/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0693 - accuracy: 0.9732\n",
            "Epoch 130/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.0590 - accuracy: 0.9779\n",
            "Epoch 131/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0647 - accuracy: 0.9744\n",
            "Epoch 132/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0658 - accuracy: 0.9740\n",
            "Epoch 133/150\n",
            "133/133 [==============================] - 15s 114ms/step - loss: 0.0592 - accuracy: 0.9765\n",
            "Epoch 134/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0605 - accuracy: 0.9757\n",
            "Epoch 135/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0649 - accuracy: 0.9766\n",
            "Epoch 136/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0543 - accuracy: 0.9796\n",
            "Epoch 137/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0567 - accuracy: 0.9770\n",
            "Epoch 138/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0577 - accuracy: 0.9794\n",
            "Epoch 139/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0550 - accuracy: 0.9781\n",
            "Epoch 140/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0602 - accuracy: 0.9779\n",
            "Epoch 141/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0538 - accuracy: 0.9801\n",
            "Epoch 142/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0589 - accuracy: 0.9751\n",
            "Epoch 143/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0570 - accuracy: 0.9793\n",
            "Epoch 144/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0649 - accuracy: 0.9746\n",
            "Epoch 145/150\n",
            "133/133 [==============================] - 11s 83ms/step - loss: 0.0594 - accuracy: 0.9790\n",
            "Epoch 146/150\n",
            "133/133 [==============================] - 11s 84ms/step - loss: 0.0546 - accuracy: 0.9771\n",
            "Epoch 147/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0544 - accuracy: 0.9794\n",
            "Epoch 148/150\n",
            "133/133 [==============================] - 12s 88ms/step - loss: 0.0569 - accuracy: 0.9791\n",
            "Epoch 149/150\n",
            "133/133 [==============================] - 11s 86ms/step - loss: 0.0542 - accuracy: 0.9797\n",
            "Epoch 150/150\n",
            "133/133 [==============================] - 11s 85ms/step - loss: 0.0531 - accuracy: 0.9797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9bded66790>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "classifier.compile(loss = tf.keras.losses.BinaryCrossentropy(), run_eagerly=True, optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "# fit network\n",
        "classifier.fit(X_train, y_train, epochs=150, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5dcb8lLX_pG",
        "outputId": "001ff57f-6219-4217-cad1-268412dacd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114/114 [==============================] - 3s 23ms/step - loss: 0.3846 - accuracy: 0.9107\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3846243619918823, 0.9106699824333191]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "classifier.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy Score = \", accuracy_score(YY_test, YY_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w7TgF2npQar",
        "outputId": "996d6757-daef-4a0d-c879-5558a63cd1fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score =  0.9106699751861043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bb4pim0fOryR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af6526e-f946-4c63-a035-0cca3bbe580d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114/114 [==============================] - 2s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "Predict = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5d2Lzj20OryS"
      },
      "outputs": [],
      "source": [
        "YY = y_test.numpy()\n",
        "YY_test = np.argmax(YY,axis = 1)\n",
        "\n",
        "YY_predict = np.argmax(Predict,axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9V-ggArOryS",
        "outputId": "ca3d93e2-9ffd-4b05-a638-7aca5b576abd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "YY_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xjUNS2KOryS",
        "outputId": "58cd8cb9-9795-4b1f-ea68-fb36478a78a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2300,  124],\n",
              "       [ 200, 1003]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "cm = confusion_matrix(YY_test, YY_predict)\n",
        "\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8ejj74NdOryS"
      },
      "outputs": [],
      "source": [
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (8,8),\n",
        "                           fontsize=14, normalize=True):\n",
        "     \n",
        "    if normalize:\n",
        "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        fmt = '.2f'\n",
        "    else:\n",
        "        fmt = 'd'\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt= fmt)\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "h0vWSUr0OryT",
        "outputId": "9d8adfa8-0990-40cd-ee51-ed0d1e22d988",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
        " #                  'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
        "   #                'X', 'Y', 'Z']\n",
        "\n",
        "\n",
        "#class_names = ['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #                  'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd'] \n",
        "\n",
        "#class_names = ['0','1','2','3','4','5','6','7','8','9','A',\n",
        " #                'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W',\n",
        "   #               'X', 'Y', 'Z','a',\n",
        "    #             'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "     #             'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
        "      #            'x', 'y', 'z']\n",
        "\n",
        "class_names = ['Not Writing','Writing']                   \n",
        "print_confusion_matrix(cm, class_names)\n",
        "plt.savefig('Confusion_Matix_.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vHx9OK1Fps_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87aaff75-85de-4fbb-9a66-1c89f1200470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not Writing       0.92      0.95      0.93      2424\n",
            "     Writing       0.89      0.83      0.86      1203\n",
            "\n",
            "    accuracy                           0.91      3627\n",
            "   macro avg       0.90      0.89      0.90      3627\n",
            "weighted avg       0.91      0.91      0.91      3627\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#report = classification_report(YY_test, YY_predict,target_names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
        " #                  'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
        "   #                'X', 'Y', 'Z'])\n",
        "\n",
        "#report = classification_report(YY_test, YY_predict,target_names=['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #                  'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd']) \n",
        "\n",
        "#report = classification_report(YY_test, YY_predict,target_names= ['0','1','2','3','4','5','6','7','8','9','A',\n",
        " #                'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #               'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W',\n",
        "   #               'X', 'Y', 'Z','a',\n",
        "    #             'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "     #             'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
        "      #            'x', 'y', 'z']) \n",
        "\n",
        "report = classification_report(YY_test, YY_predict,target_names= ['Not Writing','Writing'])\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "print(report)"
      ],
      "metadata": {
        "id": "rz2VddWb3440"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Classification_Report.txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ],
      "metadata": {
        "id": "zbfheiTd35JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_Zmh35e-OryU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e80aef9-9ce3-4cf9-f3f9-aae2d0954ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({True: 3303, False: 324})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "correct = [pred == true for pred, true in zip(YY_predict, YY_test)]\n",
        "correct = np.array(correct).flatten()\n",
        "print(Counter(correct))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EzkhhPBbOryU"
      },
      "outputs": [],
      "source": [
        "YY = np.array(y_test).flatten()\n",
        "classifiedIndexes = np.where(YY_test==YY_predict)[0]\n",
        "misclassifiedIndexes = np.where(YY_test!=YY_predict)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmS-FfHnvAL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}