{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "qRgel7ZeO0JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuG_50ZChdQA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras import utils as np_utils \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from keras import utils as np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#Importing training set\n",
        "\n",
        "X = np.load(\"/content/(N_W)X_Data.npy\",allow_pickle=True)\n",
        "Y = np.load(\"/content/(N_W)Y_Data.npy\",allow_pickle=True)\n",
        "\n",
        "X_train, X_test, y_train , y_test  = train_test_split(X, Y, test_size = 0.30, random_state = 150, shuffle=True)\n",
        "\n",
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_test = np.asarray(X_test).astype('float32')\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 196, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 196,1))\n",
        "\n",
        "#Convert data into 3d tensor\n",
        "#X_train = np.reshape(X_train,(1721,132,1))\n",
        "#X_test = np.reshape(X_test,(574,132,1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train = tf.cast(X_train,dtype=tf.float32)\n",
        "X_test = tf.cast(X_test,dtype=tf.float32)\n",
        "y_train = y_train \n",
        "y_test = y_test\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "y_train=tf.cast(y_train,dtype=tf.float32)\n",
        "y_test=tf.cast(y_test,dtype=tf.float32)\n",
        "\n",
        "\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCcImh6YHJZZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers.pooling import AveragePooling1D\n",
        "#Importing convolutional layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "#Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "#Input shape must be explicitly defined, DO NOT USE (None,shape)!!!\n",
        "\n",
        "classifier.add(Convolution1D(filters=8, kernel_size=1, activation=\"relu\")) \n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Convolution1D(filters=16, kernel_size=2, activation=\"relu\")) \n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Convolution1D(filters=16, kernel_size=3,activation=\"relu\"))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Convolution1D(filters=32, kernel_size=3,activation=\"relu\"))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "\n",
        "classifier.add(Convolution1D(filters=32, kernel_size=3,activation=\"relu\"))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#Flattening\n",
        "classifier.add(AveragePooling1D())\n",
        "classifier.add(Flatten())\n",
        "\n",
        "\n",
        "#Full Connection\n",
        "classifier.add(Dropout(0.3))\n",
        "classifier.add(Dense(2, activation = 'softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mRJnKkrUV1I"
      },
      "outputs": [],
      "source": [
        "classifier.compile(loss = tf.keras.losses.BinaryCrossentropy(), run_eagerly=True, optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "# fit network\n",
        "classifier.fit(X_train, y_train, epochs=150, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5dcb8lLX_pG"
      },
      "outputs": [],
      "source": [
        "classifier.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy Score = \", accuracy_score(YY_test, YY_predict))"
      ],
      "metadata": {
        "id": "_w7TgF2npQar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb4pim0fOryR"
      },
      "outputs": [],
      "source": [
        "Predict = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d2Lzj20OryS"
      },
      "outputs": [],
      "source": [
        "YY = y_test.numpy()\n",
        "YY_test = np.argmax(YY,axis = 1)\n",
        "\n",
        "YY_predict = np.argmax(Predict,axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9V-ggArOryS"
      },
      "outputs": [],
      "source": [
        "YY_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xjUNS2KOryS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "cm = confusion_matrix(YY_test, YY_predict)\n",
        "\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ejj74NdOryS"
      },
      "outputs": [],
      "source": [
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (8,8),\n",
        "                           fontsize=14, normalize=True):\n",
        "     \n",
        "    if normalize:\n",
        "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        fmt = '.2f'\n",
        "    else:\n",
        "        fmt = 'd'\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt= fmt)\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0vWSUr0OryT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
        " #                  'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
        "   #                'X', 'Y', 'Z']\n",
        "\n",
        "\n",
        "#class_names = ['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #                  'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd'] \n",
        "\n",
        "#class_names = ['0','1','2','3','4','5','6','7','8','9','A',\n",
        " #                'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W',\n",
        "   #               'X', 'Y', 'Z','a',\n",
        "    #             'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "     #             'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
        "      #            'x', 'y', 'z']\n",
        "\n",
        "class_names = ['Not Writing','Writing']                   \n",
        "print_confusion_matrix(cm, class_names)\n",
        "plt.savefig('Confusion_Matix_.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHx9OK1Fps_N"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#report = classification_report(YY_test, YY_predict,target_names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
        " #                  'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #                 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
        "   #                'X', 'Y', 'Z'])\n",
        "\n",
        "#report = classification_report(YY_test, YY_predict,target_names=['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #                  'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd']) \n",
        "\n",
        "#report = classification_report(YY_test, YY_predict,target_names= ['0','1','2','3','4','5','6','7','8','9','A',\n",
        " #                'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "  #               'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W',\n",
        "   #               'X', 'Y', 'Z','a',\n",
        "    #             'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "     #             'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
        "      #            'x', 'y', 'z']) \n",
        "\n",
        "report = classification_report(YY_test, YY_predict,target_names= ['Not Writing','Writing'])\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "print(report)"
      ],
      "metadata": {
        "id": "rz2VddWb3440"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Classification_Report.txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ],
      "metadata": {
        "id": "zbfheiTd35JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zmh35e-OryU"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "correct = [pred == true for pred, true in zip(YY_predict, YY_test)]\n",
        "correct = np.array(correct).flatten()\n",
        "print(Counter(correct))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzkhhPBbOryU"
      },
      "outputs": [],
      "source": [
        "YY = np.array(y_test).flatten()\n",
        "classifiedIndexes = np.where(YY_test==YY_predict)[0]\n",
        "misclassifiedIndexes = np.where(YY_test!=YY_predict)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmS-FfHnvAL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}