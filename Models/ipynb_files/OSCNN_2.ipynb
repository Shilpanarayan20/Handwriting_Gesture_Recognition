{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "cFPqbQnydjbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "8Xhso3MumejX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbfDDWJzmF6z"
      },
      "outputs": [],
      "source": [
        "def get_Prime_number_in_a_range(start, end):\n",
        "    Prime_list = []\n",
        "    for val in range(start, end + 1): \n",
        "        prime_or_not = True\n",
        "        for n in range(2, val):\n",
        "            if (val % n) == 0:\n",
        "                prime_or_not = False\n",
        "                break\n",
        "        if prime_or_not:\n",
        "            Prime_list.append(val)\n",
        "    return Prime_list\n",
        "\n",
        "\n",
        "def get_out_channel_number(paramenter_layer, in_channel, prime_list):\n",
        "    out_channel_expect = int(paramenter_layer/(in_channel*sum(prime_list)))\n",
        "    return out_channel_expect\n",
        "\n",
        "\n",
        "\n",
        "def generate_layer_parameter_list(start,end,paramenter_number_of_layer_list, in_channel = 1):\n",
        "    prime_list = get_Prime_number_in_a_range(start, end)\n",
        "    if prime_list == []:\n",
        "        print('start = ',start, 'which is larger than end = ', end)\n",
        "    input_in_channel = in_channel\n",
        "    layer_parameter_list = []\n",
        "    for paramenter_number_of_layer in paramenter_number_of_layer_list:\n",
        "        out_channel = get_out_channel_number(paramenter_number_of_layer, in_channel, prime_list)\n",
        "        \n",
        "        tuples_in_layer= []\n",
        "        for prime in prime_list:\n",
        "            tuples_in_layer.append((in_channel,out_channel,prime))\n",
        "        in_channel =  len(prime_list)*out_channel\n",
        "        \n",
        "        layer_parameter_list.append(tuples_in_layer)\n",
        "    \n",
        "    tuples_in_layer_last = []\n",
        "    first_out_channel = len(prime_list)*get_out_channel_number(paramenter_number_of_layer_list[0], input_in_channel, prime_list)\n",
        "    tuples_in_layer_last.append((in_channel,first_out_channel,start))\n",
        "    tuples_in_layer_last.append((in_channel,first_out_channel,start+1))\n",
        "    layer_parameter_list.append(tuples_in_layer_last)\n",
        "    return layer_parameter_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_Prime_number_in_a_range(2, 10)"
      ],
      "metadata": {
        "id": "jGs79ogiHQ5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwFGNJJIHo2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mask_index(kernel_length_now,largest_kernel_lenght):\n",
        "    right_zero_mast_length = math.ceil((largest_kernel_lenght-1)/2)-math.ceil((kernel_length_now-1)/2)\n",
        "    left_zero_mask_length = largest_kernel_lenght - kernel_length_now - right_zero_mast_length\n",
        "    return left_zero_mask_length, left_zero_mask_length+ kernel_length_now\n",
        "\n",
        "def creat_mask(number_of_input_channel,number_of_output_channel, kernel_length_now, largest_kernel_lenght):\n",
        "    ind_left, ind_right= calculate_mask_index(kernel_length_now,largest_kernel_lenght)\n",
        "    mask = np.ones((number_of_input_channel,number_of_output_channel,largest_kernel_lenght))\n",
        "    mask[:,:,0:ind_left]=0\n",
        "    mask[:,:,ind_right:]=0\n",
        "    return mask\n",
        "\n",
        "\n",
        "def creak_layer_mask(layer_parameter_list):\n",
        "    largest_kernel_lenght = layer_parameter_list[-1][-1]\n",
        "    mask_list = []\n",
        "    init_weight_list = []\n",
        "    bias_list = []\n",
        "    for i in layer_parameter_list:\n",
        "        conv = torch.nn.Conv1d(in_channels=i[0], out_channels=i[1], kernel_size=i[2])\n",
        "        ind_l,ind_r= calculate_mask_index(i[2],largest_kernel_lenght)\n",
        "        big_weight = np.zeros((i[1],i[0],largest_kernel_lenght))\n",
        "        big_weight[:,:,ind_l:ind_r]= conv.weight.detach().numpy()\n",
        "        \n",
        "        bias_list.append(conv.bias.detach().numpy())\n",
        "        init_weight_list.append(big_weight)\n",
        "        \n",
        "        mask = creat_mask(i[1],i[0],i[2], largest_kernel_lenght)\n",
        "        mask_list.append(mask)\n",
        "        \n",
        "    mask = np.concatenate(mask_list, axis=0)\n",
        "    init_weight = np.concatenate(init_weight_list, axis=0)\n",
        "    init_bias = np.concatenate(bias_list, axis=0)\n",
        "    return mask.astype(np.float32), init_weight.astype(np.float32), init_bias.astype(np.float32)\n",
        "\n",
        "    \n",
        "class build_layer_with_layer_parameter(nn.Module):\n",
        "    def __init__(self,layer_parameters):\n",
        "        super(build_layer_with_layer_parameter, self).__init__()\n",
        "\n",
        "        os_mask, init_weight, init_bias= creak_layer_mask(layer_parameters)\n",
        "        \n",
        "        \n",
        "        in_channels = os_mask.shape[1] \n",
        "        out_channels = os_mask.shape[0] \n",
        "        max_kernel_size = os_mask.shape[-1]\n",
        "\n",
        "        self.weight_mask = nn.Parameter(torch.from_numpy(os_mask),requires_grad=False)\n",
        "        \n",
        "        self.padding = nn.ConstantPad1d((int((max_kernel_size-1)/2), int(max_kernel_size/2)), 0)\n",
        "         \n",
        "        self.conv1d = torch.nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=max_kernel_size)\n",
        "        self.conv1d.weight = nn.Parameter(torch.from_numpy(init_weight),requires_grad=True)\n",
        "        self.conv1d.bias =  nn.Parameter(torch.from_numpy(init_bias),requires_grad=True)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(num_features=out_channels)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.conv1d.weight.data = self.conv1d.weight*self.weight_mask\n",
        "        #self.conv1d.weight.data.mul_(self.weight_mask)\n",
        "        result_1 = self.padding(X)\n",
        "        result_2 = self.conv1d(result_1)\n",
        "        result_3 = self.bn(result_2)\n",
        "        result = F.relu(result_3)\n",
        "        return result    \n",
        "    \n",
        "class OS_CNN(nn.Module):\n",
        "    def __init__(self,layer_parameter_list,n_class,few_shot = True):\n",
        "        super(OS_CNN, self).__init__()\n",
        "        self.few_shot = few_shot\n",
        "        self.layer_parameter_list = layer_parameter_list\n",
        "        self.layer_list = []\n",
        "        \n",
        "        \n",
        "        for i in range(len(layer_parameter_list)):\n",
        "            layer = build_layer_with_layer_parameter(layer_parameter_list[i])\n",
        "            self.layer_list.append(layer)\n",
        "        \n",
        "        self.net = nn.Sequential(*self.layer_list)\n",
        "            \n",
        "        self.averagepool = nn.AdaptiveAvgPool1d(1)\n",
        "        \n",
        "        out_put_channel_numebr = 0\n",
        "        for final_layer_parameters in layer_parameter_list[-1]:\n",
        "            out_put_channel_numebr = out_put_channel_numebr+ final_layer_parameters[1] \n",
        "            \n",
        "        self.hidden = nn.Linear(out_put_channel_numebr, n_class)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        X = self.net(X)\n",
        "\n",
        "        X = self.averagepool(X)\n",
        "        X = X.squeeze_(-1)\n",
        "\n",
        "        if not self.few_shot:\n",
        "            X = self.hidden(X)\n",
        "        return X\n",
        "        "
      ],
      "metadata": {
        "id": "xVPYeiN8mfte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from os.path import dirname\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "class OS_CNN_easy_use():\n",
        "\n",
        "    def __init__(self,\n",
        "                 device,\n",
        "                 start_kernel_size = 1,\n",
        "                 Max_kernel_size = 100,\n",
        "                 paramenter_number_of_layer_list = [8*128, 5*128*256 + 2*256*128],\n",
        "                 max_epoch = 2000,\n",
        "                 batch_size=16,\n",
        "                 print_result_every_x_epoch = 50,\n",
        "                 learning_rate = 0.001\n",
        "                ):\n",
        "\n",
        "        super(OS_CNN_easy_use, self).__init__()\n",
        "\n",
        "        \n",
        "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.start_kernel_size = start_kernel_size\n",
        "        self.Max_kernel_size = Max_kernel_size\n",
        "        self.paramenter_number_of_layer_list = paramenter_number_of_layer_list\n",
        "        self.max_epoch = max_epoch\n",
        "        self.batch_size = batch_size\n",
        "        self.print_result_every_x_epoch = print_result_every_x_epoch\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.OS_CNN = None\n",
        "\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "\n",
        "        print('code is running on ',self.device)\n",
        "\n",
        "\n",
        "        # covert numpy to pytorch tensor and put into gpu\n",
        "        X_train = torch.from_numpy(X_train)\n",
        "        X_train.requires_grad = False\n",
        "        X_train = X_train.to(self.device)\n",
        "        y_train = torch.from_numpy(y_train).to(self.device)\n",
        "\n",
        "\n",
        "        X_test = torch.from_numpy(X_val)\n",
        "        X_test.requires_grad = False\n",
        "        X_test = X_test.to(self.device)\n",
        "        y_test = torch.from_numpy(y_val).to(self.device)\n",
        "\n",
        "\n",
        "        # add channel dimension to time series data\n",
        "        if len(X_train.shape) == 2:\n",
        "            X_train = X_train.unsqueeze_(1)\n",
        "            X_test = X_test.unsqueeze_(1)\n",
        "\n",
        "        input_shape = X_train.shape[-1]\n",
        "        n_class = max(y_train) + 1\n",
        "        receptive_field_shape= min(int(X_train.shape[-1]/4),self.Max_kernel_size)\n",
        "\n",
        "        # generate parameter list\n",
        "        layer_parameter_list = generate_layer_parameter_list(self.start_kernel_size,\n",
        "                                                             receptive_field_shape,\n",
        "                                                             self.paramenter_number_of_layer_list,\n",
        "                                                             in_channel = int(X_train.shape[1]))\n",
        "\n",
        "\n",
        "        torch_OS_CNN = OS_CNN(layer_parameter_list, n_class.item(), False).to(self.device)\n",
        "\n",
        "        # save_initial_weight\n",
        "        #torch.save(torch_OS_CNN.state_dict(), self.Initial_model_path)\n",
        "\n",
        "\n",
        "        # loss, optimizer, scheduler\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(torch_OS_CNN.parameters(),lr=self.learning_rate)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50, min_lr=0.0001)\n",
        "\n",
        "        # build dataloader\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=max(int(min(X_train.shape[0] / 10, self.batch_size)),2), shuffle=True)\n",
        "        test_dataset = TensorDataset(X_test, y_test)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=max(int(min(X_train.shape[0] / 10, self.batch_size)),2), shuffle=False)\n",
        "\n",
        "\n",
        "        torch_OS_CNN.train()\n",
        "\n",
        "        for i in range(self.max_epoch):\n",
        "            for sample in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                y_predict = torch_OS_CNN(sample[0])\n",
        "                output = criterion(y_predict, sample[1])\n",
        "                output.backward()\n",
        "                optimizer.step()\n",
        "            scheduler.step(output)\n",
        "\n",
        "            if eval_condition(i,self.print_result_every_x_epoch):\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    print('epoch =',i, 'lr = ', param_group['lr'])\n",
        "                torch_OS_CNN.eval()\n",
        "                acc_train = eval_model(torch_OS_CNN, train_loader)\n",
        "                acc_test = eval_model(torch_OS_CNN, test_loader)\n",
        "                torch_OS_CNN.train()\n",
        "                print('train_acc=\\t', acc_train, '\\t test_acc=\\t', acc_test, '\\t loss=\\t', output.item())\n",
        "                sentence = 'train_acc=\\t'+str(acc_train)+ '\\t test_acc=\\t'+str(acc_test)+'\\t loss=\\t'+str(output.item())\n",
        "                #torch.save(torch_OS_CNN.state_dict(), self.model_save_path)\n",
        "\n",
        "        #torch.save(torch_OS_CNN.state_dict(), self.model_save_path)\n",
        "        self.OS_CNN = torch_OS_CNN\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "\n",
        "        X_test = torch.from_numpy(X_test)\n",
        "        X_test.requires_grad = False\n",
        "        X_test = X_test.to(self.device)\n",
        "\n",
        "        if len(X_test.shape) == 2:\n",
        "            X_test = X_test.unsqueeze_(1)\n",
        "\n",
        "        test_dataset = TensorDataset(X_test)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=max(int(min(X_test.shape[0] / 10, self.batch_size)),2), shuffle=False)\n",
        "\n",
        "        self.OS_CNN.eval()\n",
        "\n",
        "        predict_list = np.array([])\n",
        "        for sample in test_loader:\n",
        "            y_predict = self.OS_CNN(sample[0])\n",
        "            y_predict = y_predict.detach().cpu().numpy()\n",
        "            y_predict = np.argmax(y_predict, axis=1)\n",
        "            predict_list = np.concatenate((predict_list, y_predict), axis=0)\n",
        "\n",
        "        return predict_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SZIse5Q6mjl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from os.path import dirname\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def eval_condition(iepoch,print_result_every_x_epoch):\n",
        "    if (iepoch + 1) % print_result_every_x_epoch == 0:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def eval_model(model, dataloader):\n",
        "    predict_list = np.array([])\n",
        "    label_list = np.array([])\n",
        "    for sample in dataloader:\n",
        "        y_predict = model(sample[0])\n",
        "        y_predict = y_predict.detach().cpu().numpy()\n",
        "        y_predict = np.argmax(y_predict, axis=1)\n",
        "        predict_list = np.concatenate((predict_list, y_predict), axis=0)\n",
        "        label_list = np.concatenate((label_list, sample[1].detach().cpu().numpy()), axis=0)\n",
        "    acc = accuracy_score(predict_list, label_list)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "BbHSu5g_HHQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from scipy.signal import resample\n",
        "import seaborn as sns\n",
        "\n",
        "CANVAS_HEIGHT = 400\n",
        "CANVAS_LENGTH = 800\n",
        "CANVAS_X_MIN = -80\n",
        "CANVAS_X_MAX = 80\n",
        "CANVAS_Y_MIN = -70\n",
        "CANVAS_Y_MAX = 70\n",
        "CANVAS_X_MULTIPLIER = CANVAS_LENGTH / (CANVAS_X_MAX - CANVAS_X_MIN)\n",
        "CANVAS_Y_MULTIPLIER = -CANVAS_HEIGHT / (CANVAS_Y_MAX - CANVAS_Y_MIN)\n",
        "RESAMPLE_VAL = 60\n",
        "\n",
        "def decode_number2(number):\n",
        "    switcher = { 0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7',\n",
        "                 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E',\n",
        "                 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L',\n",
        "                 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S',\n",
        "                 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z',\n",
        "                 36: 'a', 37: 'b', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h',\n",
        "                 43: 'n', 44: 'q', 45: 'r', 46: 't' }\n",
        "    return switcher.get(number,str(number))\n",
        "\n",
        "def decode_number(number):\n",
        "    switcher = { 0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7',\n",
        "                 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E',\n",
        "                 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L',\n",
        "                 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S',\n",
        "                 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z',\n",
        "                 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g',\n",
        "                 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n',\n",
        "                 50: 'o', 51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u',\n",
        "                 57: 'v', 58: 'w', 59: 'x', 60: 'y', 61: 'z'}\n",
        "    return switcher.get(number,str(number))\n",
        "\n",
        "def characters_47_classes_to_36(number):\n",
        "    switcher = { 36: 10, 37: 11, 38: 13, 39: 14, 40: 15, 41: 16, 42: 17,\n",
        "                 43: 23, 44: 26, 45: 27, 46: 29 }\n",
        "    return switcher.get(number,number)\n",
        "\n",
        "def char_to_num(symbol):\n",
        "    switcher = {'0':0, '1':1, '2':2, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, 'A':10,\n",
        "               'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16, 'H':17, 'I':18, 'J':19, 'K':20, 'L':21,\n",
        "               'M':22, 'N':23, 'O':24, 'P':25, 'Q':26, 'R':27, 'S':28, 'T':29, 'U':30, 'V':31, 'W':32,\n",
        "               'X':33, 'Y':34, 'Z':35}\n",
        "    return switcher.get(symbol,symbol)\n",
        "\n",
        "def char_to_num2(symbol):\n",
        "    switcher = {'a': 0, 'b':1, 'd':2, 'e':3, 'f':4, 'g':5, 'h':6, 'n':7, 'q':8,\n",
        "                'r': 9, 't': 10, '0':11, '1':12, '2':13, '3':14, '4':15, '5':16,\n",
        "                '6':17, '7':18, '8':19, '9':20, 'A':21, 'B':22, 'C':23, 'D':24,\n",
        "                'E':25, 'F':26, 'G':27, 'H':28, 'I':29, 'J':30, 'K':31, 'L':32,\n",
        "                'M':33, 'N':34, 'O':35, 'P':36, 'Q':37, 'R':38, 'S':39, 'T':40,\n",
        "                'U':41, 'V':42, 'W':43, 'X':44, 'Y':45, 'Z':46}\n",
        "    return switcher.get(symbol,symbol)\n",
        "\n",
        "def characters_merged_37_classes(label):\n",
        "    \"\"\" changes the lower case letter to upper case letters where upper\n",
        "        and lower letters are similar\n",
        "    label: ASCII character\n",
        "        ASCII character a to z\n",
        "\n",
        "    returns new ASCII character in upper case if letter is detected\n",
        "    \"\"\"\n",
        "    switcher = { 'c': 'C', 'i': 'I', 'j': 'J', 'k': 'K', 'l': 'L', 'm': 'M',\n",
        "                 'o': 'O', 'p': 'P', 's': 'S', 'u': 'U', 'v': 'V', 'w': 'W',\n",
        "                 'x': 'X', 'y': 'Y', 'z': 'Z' }\n",
        "\n",
        "    return switcher.get(label,label)\n",
        "\n",
        "\n",
        "def characters_merged_26_classes(label):\n",
        "    \"\"\" changes the lower case letter to upper case letters\n",
        "    label: ASCII character\n",
        "        ASCII character a to z\n",
        "\n",
        "    returns new ASCII character in upper case if letter is detected\n",
        "    \"\"\"\n",
        "    switcher = { 'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D', 'e': 'E', 'f': 'F',\n",
        "                 'g': 'G', 'h': 'H', 'i': 'I', 'j': 'J', 'k': 'K', 'l': 'L',\n",
        "                 'm': 'M', 'n': 'N', 'o': 'O', 'p': 'P', 'q': 'Q', 'r': 'R',\n",
        "                 's': 'S', 't': 'T', 'u': 'U', 'v': 'V', 'w': 'W', 'x': 'X',\n",
        "                 'y': 'Y', 'z': 'Z' }\n",
        "\n",
        "    return switcher.get(label,label)\n",
        "\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (50,50),\n",
        "                           fontsize=14, normalize=True):\n",
        "    if normalize:\n",
        "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        fmt = '.2f'\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        fmt = 'd'\n",
        "        print(\"Confusion matrix, without normalization\")\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt= fmt)\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n"
      ],
      "metadata": {
        "id": "UOpfqF0I-Lgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "X = np.load(\"/content/W_W_Data.npy\",allow_pickle=True)\n",
        "Y = np.load(\"/content/W_Y_(62).npy\",allow_pickle=True)\n",
        "\n",
        "#X_test = np.load(\"/content/X_test.npy\",allow_pickle=True)\n",
        "#y_test = np.load(\"/content/y_test.npy\",allow_pickle=True)\n",
        "\n",
        "X_train, X_test, y_train , y_test  = train_test_split(X, Y, test_size = 0.30, random_state = 150, shuffle=True)\n",
        "X_train, X_validate, y_train , y_validate  = train_test_split(X_train, y_train, test_size = 0.001, random_state = 150)\n",
        "\n",
        "# creat model and log save place\n",
        "model = OS_CNN_easy_use(\n",
        "         # dataset_name for creat log under Result_log_folder\n",
        "        device = \"cuda:0\",                     # Gpu\n",
        "        max_epoch = 75,                        # In our expirement the number is 2000 for keep it same with FCN for the example dataset 500 will be enough\n",
        "        paramenter_number_of_layer_list = [8*128*X_train.shape[1], 5*128*256 + 2*256*128],\n",
        "        batch_size=64,\n",
        "        print_result_every_x_epoch = 1,\n",
        "        learning_rate=0.001\n",
        "        )\n",
        "\n",
        "\n",
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_validate = np.asarray(X_validate).astype('float32')\n",
        "X_test = np.asarray(X_test).astype('float32')\n",
        "\n",
        "#y_train = tf.keras.utils.to_categorical(y_train)\n",
        "#y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "#y_train = np.asarray(y_train).astype('float32')\n",
        "#y_test = np.asarray(y_test).astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "X_validate.shape\n",
        "y_train = np.reshape(y_train,(9953,))\n",
        "y_validate = np.reshape(y_validate,(10,))\n",
        "y_test = np.reshape(y_test,(4270,))\n",
        "\n",
        "\n",
        "#X_train = np.reshape(X_train,(9953,6,615))\n",
        "#X_validate = np.reshape(X_validate,(10,6,615)).T\n",
        "#X_test = np.reshape(X_test,(4270,6,615))"
      ],
      "metadata": {
        "id": "e_k0OlYomoA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,X_validate,y_validate)\n",
        "y_predict = model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "aDK1Iu1dAvbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpKdMDLRFryv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_predict, y_test)\n",
        "print(acc)\n"
      ],
      "metadata": {
        "id": "YaWvIdp3RVhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy Score = \", accuracy_score(y_test, y_predict))"
      ],
      "metadata": {
        "id": "Q5lo3taNMars"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_predict)\n",
        "#class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A','B', 'C', 'D', 'E', 'F', 'G', 'H', \n",
        "    #               'I', 'J', 'K', 'L','M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W','X', 'Y', 'Z']\n",
        "\n",
        "\n",
        "#class_names = ['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        " #               'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "  #                 'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd'] \n",
        "\n",
        "class_names = ['0','1','2','3','4','5','6','7','8','9','A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "              'M', 'N', 'O', 'P', 'Q', 'R', 'S','T', 'U', 'V', 'W','X', 'Y', 'Z','a','b', 'c', 'd', 'e', 'f', 'g', 'h',\n",
        "                'i', 'j', 'k', 'l','m', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w','x', 'y', 'z'] \n",
        "print_confusion_matrix(conf_matrix, class_names)\n",
        "plt.savefig('Confusion_Matix(62).png', dpi=300)"
      ],
      "metadata": {
        "id": "lRoOUCCK_cUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_predict,target_names= ['0,O,o','1,I,i,l ','2,Z,z','3','4','5,S,s','6,G','7','8','9,a,g,q','A',\n",
        "                'B', 'C,c', 'D,P,p,b', 'E,e', 'F,f', 'H,h', 'J,j ', 'K,k', 'L',\n",
        "                   'M,m', 'N,n', 'Q','R','T,t', 'U,V,u,v', 'W,w','X,x', 'Y,y', 'd'] )"
      ],
      "metadata": {
        "id": "jJIPNWNp_oku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "print(report)"
      ],
      "metadata": {
        "id": "gTsvMjieT5Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Classification_Report(30).txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ],
      "metadata": {
        "id": "WrjflY9LT78p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "correct = [pred == true for pred, true in zip(y_predict, y_test)]\n",
        "correct = np.array(correct).flatten()\n",
        "print(Counter(correct))"
      ],
      "metadata": {
        "id": "b6DiRiI4UAnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YY = np.array(y_test).flatten()\n",
        "classifiedIndexes = np.where(y_test==y_predict)[0]\n",
        "misclassifiedIndexes = np.where(y_test!=y_predict)[0]"
      ],
      "metadata": {
        "id": "ZkKH1odQIwPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MM = misclassifiedIndexes"
      ],
      "metadata": {
        "id": "slorUM5ZIwSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OVh-VVY4JQ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "  \n",
        "for i in MM:\n",
        "  A = i\n",
        "  P = y_predict[A]\n",
        "  Y = y_test[A]\n",
        "  x_test = np.reshape(X_test,(4270,2,66))\n",
        "  X = x_test\n",
        "  XX = X[A] \n",
        "\n",
        "  x = XX[0]\n",
        "  y= XX[1]\n",
        "\n",
        "  plt.plot(x, y)\n",
        "\n",
        "  #plt.plot(x, y)\n",
        "  plt.title( \".\" + str(i) + \".\" + str(Y) + \".\" + str(P) + \".\")\n",
        "  plt.savefig(\"/content/sample_data/Result_62/\" + str(i) + \".\" + str(Y) + \".\" + str(P) + \".png\")\n",
        "  plt.clf()\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "e7LZ_yW9IwUt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}